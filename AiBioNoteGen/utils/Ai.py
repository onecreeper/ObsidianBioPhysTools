import base64
import json
import requests
import logging
import os
from openai import OpenAI
from typing import List, Optional, Union

# log
current_dir = os.path.dirname(__file__)
log_dir = os.path.join(current_dir, '..', 'log')
os.makedirs(log_dir, exist_ok=True)
log_file_path = os.path.join(log_dir, 'Ai.log')
logging.basicConfig(
    filename=log_file_path,
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    encoding='utf-8'
)


class LLM:
    def __init__(self, api_key, base_url, model_name, system_prompt = "ä½¿ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜"):
        
        self.api_key = api_key
        self.base_url = base_url
        self.model_name = model_name
        self.messages = [{"role": "system", "content": system_prompt}]

    def format_chinese_response(self, text):
        """æ ¼å¼åŒ–ä¸­æ–‡å›ç­”"""
        # åˆ†æ®µå¤„ç†
        paragraphs = text.split('\n')
        formatted_paragraphs = []
        
        for p in paragraphs:
            if p.strip():
                # ä¸ºæ¯ä¸ªæ®µè½æ·»åŠ ç¼©è¿›å’Œæ ¼å¼
                formatted_p = "    " + p.strip()
                formatted_paragraphs.append(formatted_p)
        
        # æ·»åŠ è£…é¥°æ€§è¾¹æ¡†
        width = max(len(p) for p in formatted_paragraphs) if formatted_paragraphs else 20
        border = "â”" * width
        
        formatted_text = f"\n{border}\n"
        for p in formatted_paragraphs:
            formatted_text += f"{p}\n"
        formatted_text += f"{border}\n"
        
        return formatted_text
    
    def _prepare_message_content(self, text: str, images: Optional[Union[str, List[str]]] = None):
        """å‡†å¤‡æ¶ˆæ¯å†…å®¹ï¼Œæ”¯æŒçº¯æ–‡æœ¬æˆ–æ–‡æœ¬+å›¾ç‰‡
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            images: å•ä¸ªå›¾ç‰‡æˆ–å›¾ç‰‡åˆ—è¡¨ï¼Œå¯ä»¥æ˜¯URLæˆ–base64ç¼–ç 
        
        Returns:
            æ ¼å¼åŒ–åçš„æ¶ˆæ¯å†…å®¹
        """
        if images is None:
            return text

        if isinstance(images, str):
            images = [images]
        
        content = [{"type": "text", "text": text}]
        
        for img in images:
            if img.startswith("http://") or img.startswith("https://"):
                content.append({
                    "type": "image_url", 
                    "image_url": {"url": img}
                })
            elif img.startswith("data:image"):
                content.append({
                    "type": "image_url", 
                    "image_url": {"url": img}
                })
            else:
                content.append({
                    "type": "image_url", 
                    "image_url": {"url": f"data:image/jpeg;base64,{img}"}
                })
        return content
        
    def chat(self, text: str, images: Optional[Union[str, List[str]]] = None, streaming_output: bool = True) -> str | None:
        """ä¸LLMè¿›è¡Œå¯¹è¯ï¼Œæ”¯æŒæ–‡æœ¬å’Œå›¾ç‰‡è¾“å…¥

        Args:
            text (str): æ–‡æœ¬æ¶ˆæ¯
            images (Optional[Union[str, List[str]]]): å•ä¸ªå›¾ç‰‡æˆ–å›¾ç‰‡åˆ—è¡¨ï¼Œå¯ä»¥æ˜¯URLæˆ–base64ç¼–ç 
            streaming_output (bool, optional): æ˜¯å¦æµå¼è¾“å‡º. Defaults to True.

        Returns:
            str | None: aiçš„å›ç­”ï¼ŒNoneä¸ºå¼‚å¸¸
        """
        client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
        )

        reasoning_content = ""
        answer_content = ""
        is_answering = False

        # å‡†å¤‡æ¶ˆæ¯å†…å®¹
        message_content = self._prepare_message_content(text, images)
        self.messages.append({"role": "user", "content": message_content})

        try:
            completion = client.chat.completions.create(
                model=self.model_name,
                messages=self.messages,
                stream=True,
            )
            
            if streaming_output:
                print("\n" + "="*50)
                print("ğŸ¤” æ€è€ƒè¿‡ç¨‹:")
                print("="*50)
            
            for chunk in completion:
                if not chunk.choices:
                    continue
                    
                delta = chunk.choices[0].delta
                # å¤„ç†æ€è€ƒè¿‡ç¨‹
                if hasattr(delta, 'reasoning_content') and delta.reasoning_content is not None:
                    reasoning_content += delta.reasoning_content
                    if streaming_output:
                        print(delta.reasoning_content, end='', flush=True)
                else:
                    # å¤„ç†å›å¤å†…å®¹
                    if hasattr(delta, 'content') and delta.content is not None:
                        if delta.content != "" and is_answering is False:
                            is_answering = True
                            if streaming_output:
                                print("\n" + "="*50)
                                print("ğŸ’¡ å›ç­”ç»“æœ:")
                                print("="*50)
                        answer_content += delta.content
                        if streaming_output:
                            print(delta.content, end='', flush=True)
            
            if streaming_output:
                print("\n" + "="*50)

            # å°†AIçš„å›å¤æ·»åŠ åˆ°æ¶ˆæ¯å†å²ä¸­
            self.messages.append({"role": "assistant", "content": answer_content})
            
            # è®°å½•æ—¥å¿—
            log_msg = f"å¯¹è¯ - ç”¨æˆ·: {text}"
            if images:
                img_count = 1 if isinstance(images, str) else len(images)
                log_msg += f" (åŒ…å«{img_count}å¼ å›¾ç‰‡)"
            logging.info(log_msg)
            logging.info(f"å¯¹è¯ - AI: {answer_content[:100]}...")
            
            formatted_answer = self.format_chinese_response(answer_content)
            return formatted_answer
            
        except Exception as e:
            logging.error(f"èŠå¤©æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return None
    
    def ask(self, text: str, images: Optional[Union[str, List[str]]] = None, streaming_output: bool = True) -> str | None:
        """å•æ¬¡æé—®æ–¹æ³•ï¼Œä¸è®°å½•å¯¹è¯å†å²
        
        Args:
            text (str): æ–‡æœ¬æ¶ˆæ¯
            images (Optional[Union[str, List[str]]]): å•ä¸ªå›¾ç‰‡æˆ–å›¾ç‰‡åˆ—è¡¨ï¼Œå¯ä»¥æ˜¯URLæˆ–base64ç¼–ç 
            streaming_output (bool, optional): æ˜¯å¦æµå¼è¾“å‡º. Defaults to True.
        
        Returns:
            str | None: aiçš„å›ç­”ï¼ŒNoneä¸ºå¼‚å¸¸
        """
        client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
        )
        
        reasoning_content = ""
        answer_content = ""
        is_answering = False
        
        # åˆ›å»ºä¸´æ—¶æ¶ˆæ¯åˆ—è¡¨
        temp_messages = [{"role": "system", "content": self.messages[0]["content"]}]
        
        # å‡†å¤‡æ¶ˆæ¯å†…å®¹
        message_content = self._prepare_message_content(text, images)
        temp_messages.append({"role": "user", "content": message_content})
        
        try:
            completion = client.chat.completions.create(
                model=self.model_name,
                messages=temp_messages,
                stream=True,
            )
            
            if streaming_output:
                print("\n" + "="*50)
                print("ğŸ¤” æ€è€ƒè¿‡ç¨‹:")
                print("="*50)
            
            for chunk in completion:
                if not chunk.choices:
                    continue
                    
                delta = chunk.choices[0].delta
                # å¤„ç†æ€è€ƒè¿‡ç¨‹
                if hasattr(delta, 'reasoning_content') and delta.reasoning_content is not None:
                    reasoning_content += delta.reasoning_content
                    if streaming_output:
                        print(delta.reasoning_content, end='', flush=True)
                else:
                    # å¤„ç†å›å¤å†…å®¹
                    if hasattr(delta, 'content') and delta.content is not None:
                        if delta.content != "" and is_answering is False:
                            is_answering = True
                            if streaming_output:
                                print("\n" + "="*50)
                                print("ğŸ’¡ å›ç­”ç»“æœ:")
                                print("="*50)
                        answer_content += delta.content
                        if streaming_output:
                            print(delta.content, end='', flush=True)
            
            if streaming_output:
                print("\n" + "="*50)
            
            # è®°å½•æ—¥å¿—
            log_msg = f"å•æ¬¡æé—®: {text}"
            if images:
                img_count = 1 if isinstance(images, str) else len(images)
                log_msg += f" (åŒ…å«{img_count}å¼ å›¾ç‰‡)"
            logging.info(log_msg)
            logging.info(f"AIå›ç­”: {answer_content[:100]}...")
            
            formatted_answer = self.format_chinese_response(answer_content)
            return formatted_answer
            
        except Exception as e:
            logging.error(f"å•æ¬¡æé—®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return None

    def clear_history(self):
        """æ¸…é™¤å¯¹è¯å†å²ï¼Œåªä¿ç•™ç³»ç»Ÿæç¤º"""
        self.messages = [self.messages[0]]
        logging.info("å¯¹è¯å†å²å·²æ¸…é™¤")

    def get_history(self):
        """è·å–å½“å‰å¯¹è¯å†å²"""
        return self.messages

    def get_history_count(self):
        """è·å–å¯¹è¯è½®æ•°ï¼ˆä¸åŒ…æ‹¬ç³»ç»Ÿæç¤ºï¼‰"""
        return (len(self.messages) - 1) // 2


def encode_image(image_path: str) -> str:
    """å°†æœ¬åœ°å›¾ç‰‡ç¼–ç ä¸ºbase64
    
    Args:
        image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        
    Returns:
        base64ç¼–ç çš„å­—ç¬¦ä¸²
    """
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')


def main():
    qvq = LLM(
        "sk-sbsbsbsbsbsbsbsbsbsbsbsbsbsbsbsbsbsbsbsb", 
        "https://dashscope.aliyuncs.com/compatible-mode/v1", 
        "qvq-max", 
        "ä½¿ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜"
    )
    images = [encode_image("AiBioNoteGen/utils/1.jpg"), encode_image("AiBioNoteGen/utils/2.jpg")]
    qvq.chat("ä½ å¥½,ä»‹ç»ä¸‹è¿™äº›å›¾ç‰‡",images)



if __name__ == '__main__':
    main()
